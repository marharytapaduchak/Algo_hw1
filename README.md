## 1. Дані та операції

Модель: ```Student { m_name, m_surname, m_email, m_birth_*, m_group, m_rating, m_phone_number }```.

Операції задачі ІІ (змішуються у пропорції A:B:C = 2:10:30):

```top100(out)``` — повернути 100 студентів з найбільшим m_rating.

```set_rating_by_email(email, rating)``` — оновити рейтинг за m_email.

```best_group_by_avg()``` — знайти групу з найбільшим середнім рейтингом.

## 2. Варіант 1 (V1): vector + unordered_map (email→Student*), розрахунки «на льоту»

### Структури даних

```vector<Student> all``` — повний список.

```unordered_map<string, Student*> byEmail``` — швидкий доступ до студента за email (O(1) очікувано).

### Як реалізовані операції

```top100```: копіюємо ```all``` → повне сортування за ```m_rating``` (O(n log n)) → беремо перші 100.

```set_rating_by_email```: шукаємо в ```byEmail``` та просто змінюємо поле ```m_rating``` (O(1)).

```best_group_by_avg```: кожного разу проходимо ```all```, рахуємо суму/кількість у ```unordered_map<group, (sum,cnt)>``` та беремо максимум (O(n)).

### Плюси/мінуси

+ Простота реалізації.

− Дорога операція ```top100``` (O(n log n)) при великому n.

− ```best_group_by_avg``` усе перераховує щоразу (O(n)).

Коли добре? Коли масово оновлюємо рейтинги, а ```top100``` і ```best_group_by_avg``` викликаються відносно рідко або ```n``` невелике.

## 3. Варіант 2 (V2): set<RatingNode> для топів + агрегати по групах

### Структури даних

```vector<Student> all``` — дані.

```unordered_map<string, Student*> byEmail``` — швидкий доступ за email.

```set<RatingNode>``` — самобалансне дерево, впорядковане за спаданням ```m_rating``` (через перевернутий компаратор).
У вузлі — вказівник ```Student*```, отже ключ змінюється при зміні рейтингу.

```unordered_map<string, GroupAverage> groups``` — постійно підтримуємо суму та лічильник по групах.

### Як реалізовані операції

```top100```: просто ітеруємо початок ```set``` і беремо перші 100 (O(100)) — дуже швидко.

```set_rating_by_email```:

```erase(RatingNode{student})``` зі set (O(log n)),

оновлюємо ```groups[group].sum``` (O(1)),

переприсвоюємо ```m_rating```,

```insert``` назад у ```set``` (O(log n)).

```best_group_by_avg```: однопрохідний пошук максимуму по groups — дуже швидко.

### Плюси/мінуси

+ Миттєвий ```top100``` (читання з уже відсортованої структури).

+ ```best_group_by_avg``` швидкий (агрегати підтримуються інкрементально).

− Кожне оновлення рейтингу коштує два дерева-операції (erase+insert) → O(log n) на апдейт.

Коли добре? Коли часто питають топ-100 і середню групи і n великий. Ціна оновлень окупається швидкими запитами.

## 4. Варіант 3 (V3): unordered_map (email→index) + min-heap на 100 + агрегати по групах

### Структури даних

```vector<Student> all``` — дані.

```unordered_map<string, size_t> byEmail``` — email → індекс у all (O(1)).

```priority_queue<HeapEl, …, MinHeapComparator> topHeap``` — мін-купа фіксованого розміру 100.
На вершині — найменший рейтинг серед топ-100; легка заміна коли з’являється кращий.

```unordered_map<string, GroupAverage> groups```— як у V2, підтримка середніх.

### Як реалізовані операції

```top100```: копіюємо купу (auto copy = topHeap), виймаємо елементи (до 100) і сортуємо їх для красивого спадання — O(100 log 100) + O(100 log 100).

```set_rating_by_email```:

знаходимо idx у O(1),

оновлюємо агрегат групи (O(1)),

змінюємо ```all[idx].m_rating```,

викликаємо ```pushToTop(idx)```:
• якщо в купі <100 — просто кладемо;
• якщо повна і новий рейтинг > мінімуму — замінюємо вершину.
Це O(log 100) ≈ O(1) амортизовано, але із «застарілими» елементами: старі копії індексів з попереднім рейтингом можуть лежати в купі; ми «лікуємо» це тим, що не читаємо «основну» купу напряму, а працюємо з копією і беремо факт рейтингу з ```all[idx]```. Так correctness зберігається, але інколи купа може мати dubplicate-індекси.

```best_group_by_avg```: як у V2, дуже швидко.

### Плюси/мінуси

+ Оновлення рейтингу майже O(1) (на практиці дуже швидко).

+ ```top100``` швидкий (розмір 100 фіксований).

− Купа з «застарілими» записами потребує копіювання/фільтрації під час читання).

− Якщо масово змінюються рейтинги, у купі накопичуються старі варіанти — це не ламає відповідь, але додає невеликий оверхед під час формування виходу.

Коли добре? Коли дуже багато оновлень і великий n: оновлювати купу дешевше, ніж перелаштовувати дерево (як у V2), а читання топ-100 все одно швидке.

## 5. Методика вимірювань

Дані читаються з CSV (100 / 1 000 / 10 000 / 100 000 рядків).

Для кожного набору даних створюється екземпляр V1/V2/V3.

Функція ```run_example()``` протягом 10 секунд генерує операції у статистичній пропорції 2:10:30 (через «pattern bag» і рівноймовірний вибір індексу — це дає потрібну частку викликів у середньому).

Підраховується кількість оброблених операцій (ops) та RSS (resident set size) процесу в MB (на macOS через task_info).

Результати логуються у ```bench_ops.csv```.

## 6. Сортування (Задача ІІІ, варіант S3: m_name, m_surname)

Стандартне сортування: ```std::sort``` з компаратором, який порівнює спочатку m_name, потім m_surname.

Власний алгоритм: ти реалізувала Insertion Sort.
Для прискорення можна додати Radix Sort (якщо сортуємо за числовим полем, напр. ```m_rating```) — це реально пришвидшує. Для рядків з кирилицею Radix складніший (питання локалі і нормалізації).

## 7. Висновки

V1 — найпростіший, але масштабується гірше: top100 і «середня по групі» перераховуються щоразу. Добрий для малих n або коли оновлення майже єдині операції.

V2 — підтримує відсортований глобальний порядок (через set) та інкрементальні агрегати по групах. Читання топ-100 і середніх максимально швидкі; оновлення коштує O(log n).

V3 — заточений під дешеві оновлення: фіксована мін-купа на 100 дає майже O(1) на апдейт, при цьому читання топ-100 швидке. Працює краще за V2, коли оновлення (set_rating_by_email(...)) дуже багато.

За A:B:C = 2:10:30 і при великому n, V2/V3 значно випереджають V1. Вибір між V2 і V3 залежить від балансу «частота оновлень» vs «потреба у глобально відсортованій структурі».

Для задачі ІІІ (S3) — std::sort з українською колацією дає коректний лексикографічний порядок; власноручний Insertion Sort слугує «baseline» та повільний для великих n.
